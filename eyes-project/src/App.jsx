import { useEffect, useRef, useState } from 'react'
import { Canvas } from '@react-three/fiber'
import { OrbitControls } from '@react-three/drei'
import * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection'
import * as tf from '@tensorflow/tfjs'
import Eye from './components/Eye'
import Eyelid from './components/Eyelid'
import LoadingScreen from './components/LoadingScreen'
import BlinkDetector from './utils/BlinkDetector'
import EyeSmoothing from './utils/EyeSmoothing'
import './App.css'

function App() {
  const videoRef = useRef(null)
  const [pupilPosition, setPupilPosition] = useState({ x: 0, y: 0 })
  const [blinkState, setBlinkState] = useState(false)
  const [isModelLoaded, setIsModelLoaded] = useState(false)
  const [cameraPermission, setCameraPermission] = useState(null)
  const [eyeScale, setEyeScale] = useState(1)
  const [cameraFov, setCameraFov] = useState(50)

  const modelRef = useRef(null)
  const blinkDetectorRef = useRef(new BlinkDetector())
  const eyeSmoothingRef = useRef(new EyeSmoothing(0.4))
  const requestAnimationFrameIdRef = useRef(null)
  
  // Kamera baÅŸlatma
  useEffect(() => {
    const setupCamera = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            width: 640, 
            height: 480,
            facingMode: 'user' 
          },
          audio: false
        })
        
        if (videoRef.current) {
          videoRef.current.srcObject = stream
          setCameraPermission(true)
        }
      } catch (error) {
        console.log('Kamera eriÅŸimi reddedildi:', error)
        setCameraPermission(false)
      }
    }
    
    setupCamera()
  }, [])

  // Ekran boyutuna gÃ¶re otomatik Ã¶lÃ§eklendirme
  useEffect(() => {
    const updateScale = () => {
      const width = window.innerWidth
      const height = window.innerHeight

      // Ekran boyutuna gÃ¶re gÃ¶z Ã¶lÃ§eÄŸi
      // KÃ¼Ã§Ã¼k ekranlar (telefon): 0.6-0.8
      // Orta ekranlar (tablet): 0.8-1.0
      // BÃ¼yÃ¼k ekranlar: 1.0-1.2
      let scale = 1.0
      let fov = 50

      if (width < 375) {
        // Ã‡ok kÃ¼Ã§Ã¼k telefonlar
        scale = 0.55
        fov = 60
      } else if (width < 425) {
        // KÃ¼Ã§Ã¼k telefonlar
        scale = 0.65
        fov = 58
      } else if (width < 768) {
        // Orta boy telefonlar
        scale = 0.75
        fov = 55
      } else if (width < 1024) {
        // BÃ¼yÃ¼k telefonlar / kÃ¼Ã§Ã¼k tabletler
        scale = 0.9
        fov = 52
      } else if (width < 1440) {
        // Tabletler
        scale = 1.0
        fov = 50
      } else {
        // BÃ¼yÃ¼k ekranlar
        scale = 1.2
        fov = 48
      }

      // YÃ¼kseklik/geniÅŸlik oranÄ±na gÃ¶re ince ayar
      const aspectRatio = height / width
      if (aspectRatio > 1.8) {
        // Ã‡ok uzun ekranlar (modern telefonlar)
        scale *= 0.9
      }

      setEyeScale(scale)
      setCameraFov(fov)
    }

    updateScale()
    window.addEventListener('resize', updateScale)
    window.addEventListener('orientationchange', updateScale)

    return () => {
      window.removeEventListener('resize', updateScale)
      window.removeEventListener('orientationchange', updateScale)
    }
  }, [])

  // TensorFlow.js modeli yÃ¼kleme (MediaPipe yerine)
  useEffect(() => {
    const loadModel = async () => {
      try {
        await tf.ready()
        await tf.setBackend('webgl')

        const model = await faceLandmarksDetection.createDetector(
          faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,
          {
            runtime: 'tfjs',
            maxFaces: 1,
            refineLandmarks: true
          }
        )
        modelRef.current = model
        setIsModelLoaded(true)
        console.log('âœ… Model baÅŸarÄ±yla yÃ¼klendi (TensorFlow.js backend)')
      } catch (error) {
        console.error('Model yÃ¼klenirken hata:', error)
      }
    }

    loadModel()
  }, [])
  
  // YÃ¼z tespiti ve gÃ¶z takibi
  useEffect(() => {
    let frameCount = 0
    const detectFace = async () => {
      if (!modelRef.current || !videoRef.current || !cameraPermission) {
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
        return
      }

      // Video'nun tamamen yÃ¼klendiÄŸinden emin ol
      const video = videoRef.current
      if (video.readyState < 2 || video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
        return
      }

      try {
        const predictions = await modelRef.current.estimateFaces(video)

        frameCount++
        if (frameCount % 30 === 0) {
          console.log(`ğŸ¥ Frame ${frameCount}: ${predictions.length} yÃ¼z tespit edildi`)
        }

        if (predictions.length > 0) {
          const face = predictions[0]

          // Sol gÃ¶z ve saÄŸ gÃ¶z landmark'larÄ± (keypoints kullanarak)
          const keypoints = face.keypoints

          if (!keypoints || keypoints.length < 468) {
            console.warn('âš ï¸ Yeterli keypoint bulunamadÄ±:', keypoints?.length)
            requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
            return
          }

          // MediaPipeFaceMesh keypoint indeksleri
          // Sol gÃ¶z: 33, 160, 158, 133, 153, 144
          // SaÄŸ gÃ¶z: 362, 385, 387, 263, 373, 380
          const leftEyeIndices = [33, 160, 158, 133, 153, 144]
          const rightEyeIndices = [362, 385, 387, 263, 373, 380]

          const leftEye = leftEyeIndices.map(i => [keypoints[i].x, keypoints[i].y])
          const rightEye = rightEyeIndices.map(i => [keypoints[i].x, keypoints[i].y])
          
          // GÃ¶z merkezi hesapla
          if (leftEye && leftEye.length > 0 && rightEye && rightEye.length > 0) {
            const leftEyeCenter = {
              x: leftEye.reduce((sum, p) => sum + p[0], 0) / leftEye.length,
              y: leftEye.reduce((sum, p) => sum + p[1], 0) / leftEye.length
            }
            
            const rightEyeCenter = {
              x: rightEye.reduce((sum, p) => sum + p[0], 0) / rightEye.length,
              y: rightEye.reduce((sum, p) => sum + p[1], 0) / rightEye.length
            }
            
            // Video merkezi
            const videoCenter = {
              x: videoRef.current.videoWidth / 2,
              y: videoRef.current.videoHeight / 2
            }
            
            // GÃ¶z pozisyonunu normalleÅŸtir (-1 ile 1 arasÄ±nda)
            const rawX = (leftEyeCenter.x - videoCenter.x) / (videoCenter.x * 0.5)
            const rawY = (leftEyeCenter.y - videoCenter.y) / (videoCenter.y * 0.5)
            
            // YumuÅŸat
            const smoothed = eyeSmoothingRef.current.smooth(rawX, rawY)
            setPupilPosition({ x: smoothed.x, y: -smoothed.y })
            
            // KÄ±rpma tespiti
            const blinkResult = blinkDetectorRef.current.updateBlink(leftEye, rightEye)
            setBlinkState(blinkResult.blinkDetected)
          }
        }
        
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
      } catch (error) {
        console.error('YÃ¼z tespiti hatasÄ±:', error)
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
      }
    }
    
    if (isModelLoaded) {
      detectFace()
    }
    
    return () => {
      if (requestAnimationFrameIdRef.current) {
        cancelAnimationFrame(requestAnimationFrameIdRef.current)
      }
    }
  }, [isModelLoaded, cameraPermission])
  
  return (
    <div className="app-container">
      <video
        ref={videoRef}
        autoPlay
        playsInline
        className="camera-feed"
      />
      
      <Canvas camera={{ position: [0, 0, 2.5], fov: cameraFov }} className="canvas">
        {/* IÅŸÄ±klandÄ±rma */}
        <ambientLight intensity={0.6} />
        <directionalLight position={[5, 5, 5]} intensity={0.8} />
        <directionalLight position={[-5, -5, -5]} intensity={0.3} />
        <pointLight position={[0, 0, 5]} intensity={0.5} color="#ffffff" />

        <OrbitControls
          enableZoom={false}
          enablePan={false}
          autoRotate={!cameraPermission}
          autoRotateSpeed={2}
        />

        <group scale={[eyeScale, eyeScale, eyeScale]}>
          <Eye pupilPosition={pupilPosition} />
          <Eyelid onBlink={blinkState} />
        </group>

        {!isModelLoaded && <LoadingScreen />}
      </Canvas>
      
      <div className="info-panel">
        <div className="status">
          {cameraPermission === null && <span>Kamera baÅŸlatÄ±lÄ±yor...</span>}
          {cameraPermission === false && <span className="error">âŒ Kamera eriÅŸimi reddedildi</span>}
          {cameraPermission === true && !isModelLoaded && <span>â³ Model yÃ¼kleniyor...</span>}
          {isModelLoaded && <span className="success">âœ… CanlÄ± takip aktif</span>}
        </div>
      </div>
    </div>
  )
}

export default App
