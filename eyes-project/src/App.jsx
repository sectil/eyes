import { useEffect, useRef, useState } from 'react'
import { Canvas } from '@react-three/fiber'
import { OrbitControls } from '@react-three/drei'
import * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection'
import * as tf from '@tensorflow/tfjs'
import Eye from './components/Eye'
import Eyelid from './components/Eyelid'
import LoadingScreen from './components/LoadingScreen'
import BlinkDetector from './utils/BlinkDetector'
import EyeSmoothing from './utils/EyeSmoothing'
import './App.css'

function App() {
  const videoRef = useRef(null)
  const [pupilPosition, setPupilPosition] = useState({ x: 0, y: 0 })
  const [blinkState, setBlinkState] = useState(false)
  const [isModelLoaded, setIsModelLoaded] = useState(false)
  const [cameraPermission, setCameraPermission] = useState(null)
  const [eyeScale, setEyeScale] = useState(1)
  const [cameraFov, setCameraFov] = useState(50)

  const modelRef = useRef(null)
  const blinkDetectorRef = useRef(new BlinkDetector())
  const eyeSmoothingRef = useRef(new EyeSmoothing(0.4))
  const requestAnimationFrameIdRef = useRef(null)
  const streamRef = useRef(null)  // iOS i√ßin stream ref

  // Kamera ba≈ülatma - iOS MOBILE OPTIMIZED
  useEffect(() => {
    const setupCamera = async () => {
      try {
        // iOS Safari i√ßin optimize edilmi≈ü video ayarlarƒ±
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 640, max: 640 },
            height: { ideal: 480, max: 480 },
            facingMode: 'user',
            frameRate: { ideal: 15, max: 20 }  // iOS battery i√ßin d√º≈ü√ºk FPS
          },
          audio: false
        })

        streamRef.current = stream  // Ref'e kaydet

        if (videoRef.current) {
          videoRef.current.srcObject = stream
          videoRef.current.setAttribute('playsinline', 'true')  // iOS i√ßin critical
          videoRef.current.setAttribute('webkit-playsinline', 'true')
          setCameraPermission(true)
          console.log('üìπ Kamera ba≈ülatƒ±ldƒ± (iOS optimized)')
        }
      } catch (error) {
        console.error('‚ùå Kamera eri≈üimi reddedildi:', error)
        setCameraPermission(false)
      }
    }

    setupCamera()

    // Cleanup - iOS i√ßin √∂nemli (memory leak √∂nler)
    return () => {
      try {
        if (streamRef.current?.getTracks) {
          streamRef.current.getTracks().forEach(track => {
            if (track && typeof track.stop === 'function') {
              track.stop()
              console.log('üõë Kamera track durduruldu')
            }
          })
          streamRef.current = null
        }
        if (videoRef.current) {
          videoRef.current.srcObject = null
        }
      } catch (error) {
        console.warn('Cleanup error (safe to ignore):', error)
      }
    }
  }, [])

  // Ekran boyutuna g√∂re otomatik √∂l√ßeklendirme
  useEffect(() => {
    const updateScale = () => {
      const width = window.innerWidth
      const height = window.innerHeight

      // Ekran boyutuna g√∂re g√∂z √∂l√ßeƒüi
      // K√º√ß√ºk ekranlar (telefon): 0.6-0.8
      // Orta ekranlar (tablet): 0.8-1.0
      // B√ºy√ºk ekranlar: 1.0-1.2
      let scale = 1.0
      let fov = 50

      if (width < 375) {
        // √áok k√º√ß√ºk telefonlar
        scale = 0.55
        fov = 60
      } else if (width < 425) {
        // K√º√ß√ºk telefonlar
        scale = 0.65
        fov = 58
      } else if (width < 768) {
        // Orta boy telefonlar
        scale = 0.75
        fov = 55
      } else if (width < 1024) {
        // B√ºy√ºk telefonlar / k√º√ß√ºk tabletler
        scale = 0.9
        fov = 52
      } else if (width < 1440) {
        // Tabletler
        scale = 1.0
        fov = 50
      } else {
        // B√ºy√ºk ekranlar
        scale = 1.2
        fov = 48
      }

      // Y√ºkseklik/geni≈ülik oranƒ±na g√∂re ince ayar
      const aspectRatio = height / width
      if (aspectRatio > 1.8) {
        // √áok uzun ekranlar (modern telefonlar)
        scale *= 0.9
      }

      setEyeScale(scale)
      setCameraFov(fov)
    }

    updateScale()
    window.addEventListener('resize', updateScale)
    window.addEventListener('orientationchange', updateScale)

    return () => {
      window.removeEventListener('resize', updateScale)
      window.removeEventListener('orientationchange', updateScale)
    }
  }, [])

  // TensorFlow.js modeli y√ºkleme - iOS MOBILE OPTIMIZED
  useEffect(() => {
    let isSubscribed = true

    const loadModel = async () => {
      try {
        await tf.ready()

        // iOS i√ßin WebGL backend kullan
        await tf.setBackend('webgl')

        const model = await faceLandmarksDetection.createDetector(
          faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,
          {
            runtime: 'tfjs',
            maxFaces: 1,
            refineLandmarks: false,  // iOS'ta performans i√ßin kapalƒ±
            detectorModelUrl: undefined,  // Default lightweight model
          }
        )

        if (isSubscribed) {
          modelRef.current = model
          setIsModelLoaded(true)
          console.log('‚úÖ iOS i√ßin optimize edilmi≈ü model y√ºklendi')
          console.log('üì± Memory:', tf.memory())
        } else {
          // Component unmount olduysa model'i hemen temizle
          model.dispose?.()
        }
      } catch (error) {
        console.error('Model y√ºklenirken hata:', error)
      }
    }

    loadModel()

    // Cleanup - memory leak √∂nleme
    return () => {
      isSubscribed = false
      if (modelRef.current) {
        try {
          modelRef.current.dispose?.()
          console.log('üßπ Model temizlendi')
        } catch (e) {
          console.warn('Model cleanup error (safe to ignore):', e)
        }
        modelRef.current = null
      }
    }
  }, [])
  
  // Y√ºz tespiti ve g√∂z takibi - iOS MOBILE OPTIMIZED
  useEffect(() => {
    let frameCount = 0
    let lastDetectionTime = 0
    const DETECTION_INTERVAL = 100 // iOS i√ßin 100ms (10 FPS) - battery saving

    const detectFace = async () => {
      if (!modelRef.current || !videoRef.current || !cameraPermission) {
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
        return
      }

      // Video'nun tamamen y√ºklendiƒüinden emin ol
      const video = videoRef.current
      if (video.readyState < 2 || video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
        return
      }

      // ƒ∞lk kez video boyutlarƒ±nƒ± log'la
      if (frameCount === 0) {
        console.log('üìπ Video boyutlarƒ±:', video.videoWidth, 'x', video.videoHeight)
        console.log('üìπ Video readyState:', video.readyState)
      }

      // iOS i√ßin FPS throttling - her frame deƒüil
      const now = Date.now()
      if (now - lastDetectionTime < DETECTION_INTERVAL) {
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
        return
      }
      lastDetectionTime = now

      try {
        // TensorFlow.js inference - flipHorizontal true olmalƒ±!
        const predictions = await modelRef.current.estimateFaces(video, {
          flipHorizontal: true  // iOS √∂n kamera i√ßin √∂nemli
        })

        frameCount++
        if (frameCount % 30 === 0) {
          console.log(`üé• Frame ${frameCount}: ${predictions.length} y√ºz | Memory:`, tf.memory().numTensors)
          if (predictions.length === 0) {
            console.warn('‚ö†Ô∏è Hi√ß y√ºz tespit edilmiyor! Y√ºz√ºn√ºz kamerada g√∂r√ºn√ºyor mu?')
          }
        }

        if (predictions.length > 0) {
          const face = predictions[0]
          const keypoints = face.keypoints

          if (!keypoints || keypoints.length < 468) {
            console.warn('‚ö†Ô∏è Yeterli keypoint yok:', keypoints?.length)
            requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
            return
          }

          // Sadece g√∂z keypoints - memory i√ßin minimize
          const leftEyeIndices = [33, 160, 158, 133, 153, 144]
          const rightEyeIndices = [362, 385, 387, 263, 373, 380]

          const leftEye = leftEyeIndices.map(i => [keypoints[i].x, keypoints[i].y])
          const rightEye = rightEyeIndices.map(i => [keypoints[i].x, keypoints[i].y])
          
          // G√∂z merkezi hesapla
          if (leftEye && leftEye.length > 0 && rightEye && rightEye.length > 0) {
            const leftEyeCenter = {
              x: leftEye.reduce((sum, p) => sum + p[0], 0) / leftEye.length,
              y: leftEye.reduce((sum, p) => sum + p[1], 0) / leftEye.length
            }
            
            const rightEyeCenter = {
              x: rightEye.reduce((sum, p) => sum + p[0], 0) / rightEye.length,
              y: rightEye.reduce((sum, p) => sum + p[1], 0) / rightEye.length
            }
            
            // Video merkezi
            const videoCenter = {
              x: videoRef.current.videoWidth / 2,
              y: videoRef.current.videoHeight / 2
            }
            
            // G√∂z pozisyonunu normalle≈ütir (-1 ile 1 arasƒ±nda)
            const rawX = (leftEyeCenter.x - videoCenter.x) / (videoCenter.x * 0.5)
            const rawY = (leftEyeCenter.y - videoCenter.y) / (videoCenter.y * 0.5)
            
            // Yumu≈üat
            const smoothed = eyeSmoothingRef.current.smooth(rawX, rawY)
            setPupilPosition({ x: smoothed.x, y: -smoothed.y })
            
            // Kƒ±rpma tespiti
            const blinkResult = blinkDetectorRef.current.updateBlink(leftEye, rightEye)
            setBlinkState(blinkResult.blinkDetected)
          }
        }
        
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
      } catch (error) {
        console.error('Y√ºz tespiti hatasƒ±:', error)
        requestAnimationFrameIdRef.current = requestAnimationFrame(detectFace)
      }
    }
    
    if (isModelLoaded) {
      detectFace()
    }
    
    return () => {
      if (requestAnimationFrameIdRef.current) {
        cancelAnimationFrame(requestAnimationFrameIdRef.current)
      }
    }
  }, [isModelLoaded, cameraPermission])
  
  return (
    <div className="app-container">
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        webkit-playsinline="true"
        className="camera-feed"
        style={{ objectFit: 'cover' }}
      />
      
      <Canvas
        camera={{ position: [0, 0, 2.5], fov: cameraFov }}
        className="canvas"
        dpr={[1, 1.5]}  // iOS i√ßin pixel ratio limit - memory save
        performance={{ min: 0.5 }}  // Auto performance adjustment
        gl={{
          antialias: false,  // iOS performance
          alpha: false,
          powerPreference: 'high-performance'
        }}
      >
        {/* I≈üƒ±klandƒ±rma - iOS i√ßin optimize */}
        <ambientLight intensity={0.6} />
        <directionalLight position={[5, 5, 5]} intensity={0.8} />
        <pointLight position={[0, 0, 5]} intensity={0.4} color="#ffffff" />

        <OrbitControls
          enableZoom={false}
          enablePan={false}
          autoRotate={!cameraPermission}
          autoRotateSpeed={2}
        />

        <group scale={[eyeScale, eyeScale, eyeScale]}>
          <Eye pupilPosition={pupilPosition} />
          <Eyelid onBlink={blinkState} />
        </group>

        {!isModelLoaded && <LoadingScreen />}
      </Canvas>
      
      <div className="info-panel">
        <div className="status">
          {cameraPermission === null && <span>Kamera ba≈ülatƒ±lƒ±yor...</span>}
          {cameraPermission === false && <span className="error">‚ùå Kamera eri≈üimi reddedildi</span>}
          {cameraPermission === true && !isModelLoaded && <span>‚è≥ Model y√ºkleniyor...</span>}
          {isModelLoaded && <span className="success">‚úÖ Canlƒ± takip aktif</span>}
        </div>
      </div>
    </div>
  )
}

export default App
